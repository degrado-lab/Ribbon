{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ribbon Ribbon is a python package which simplifies the usage and pipelining of biological software. Installing and running state-of-the-art tools can be done with a simple python script. Quick Start Ready to dive in? Follow these simple steps: Installation: Get started by following our Installation Guide which details how to set up Ribbon on your system. Getting Started: Explore practical examples in our Usage Guide that demonstrate common workflows. Source Code Please visit our GitHub repo for the Ribbon source code. Ribbon is open-source, and MIT licensed.","title":"Home"},{"location":"#ribbon","text":"Ribbon is a python package which simplifies the usage and pipelining of biological software. Installing and running state-of-the-art tools can be done with a simple python script.","title":"Ribbon"},{"location":"#quick-start","text":"Ready to dive in? Follow these simple steps: Installation: Get started by following our Installation Guide which details how to set up Ribbon on your system. Getting Started: Explore practical examples in our Usage Guide that demonstrate common workflows.","title":"Quick Start"},{"location":"#source-code","text":"Please visit our GitHub repo for the Ribbon source code. Ribbon is open-source, and MIT licensed.","title":"Source Code"},{"location":"contribute/","text":"Warning \ud83d\udea7 This Page is Under Construction! \ud83d\udea7","title":"Contributing"},{"location":"cookbook/","text":"Cookbook Warning \ud83d\udea7 This page is under construction! We are still adding recipes for several Tasks . \ud83d\udea7 Chai-1 Chai-1 is a high accuracy, ligand-aware protein folding tool. It takes as input a FASTA file, and outputs a directory of folded PDB structures. Chai-1 scores are output as .npz files. Simple Fold a protein from a sequence ribbon.Chai1( fasta_file = 'my_sequence.fasta', # A single input FASTA. If there are multiple sequences, they will be folded in the same structure. output_dir = './out' # Where the outputs will be stored ).run() Advanced Fold a protein from a sequence. Include two copies of ligand ribbon.Chai1( fasta_file = 'my_sequence.fasta', # A single input FASTA. If there are multiple sequences, they will be folded in the same structure. output_dir = './out', # Where the outputs will be stored smiles_string = 'C1=CC=CC=C1', # SMILES string of our ligand num_ligands = 2, # How many copies of our ligand? device = 'gpu' # Run on GPU (necessary for Chai-1) ).run() LigandMPNN LigandMPNN is a ligand-aware tool for designing sequences for a backbone structure. It takes as input a list of PDB files, and outputs a sequence (or sequences) that are predicted to fold into that structure. While LigandMPNN is gpu-accelerated, it seems to run fast on the CPU as well. Simple Design a sequence for a backbone: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], # List of PDB files output_dir = './out' # Output directory num_designs = 5 # How many sequences should we generate? ).run() The output folder will have the following structure: output_dir/ \u251c\u2500 backbones/ # Backbone structures with labeled AAs (but no sidechains) \u251c\u2500 packed/ # (Optional) Backbone structures with packed sidechains \u251c\u2500 seqs/ # A single FASTA containing the reference sequence and all designed sequences \u2514\u2500 seqs_split/ # Individual FASTA files for each designed sequence Advanced Design a homodimeric sequence, keeping crucial residues fixed. This example uses the extra_args parameter to add extra parameters into your run command. Note that this can inject arbitrary code into your container - use with caution! ligandmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], # List of PDB files output_dir = './out' # Output directory num_designs = 5 # How many sequences should we generate? extra_args= '--fixed_residues \\\"' + RESIDUES_TO_KEEP + '\\\" --homo_oligomer 1' # Make sure to keep my catalytric residues, and make two chains identical. ) RaptorX-Single RaptorX-Single is a fast protein folding tool. It can fold small structures in as little as 5 seconds, after an initial loading period. It takes as input a FASTA file (or directory containing FASTAs), and outputs a directory of folded PDB structures. Simple Fold a directory of FASTA files ribbon.RaptorXSingle( fasta_file_or_dir = './my_FASTA_directory/', output_dir = './out' ).run() Advanced Fold a directory of FASTA files using a non-default model checkpoint (param). Run on the CPU (slower; GPU is default). ribbon.RaptorXSingle( fasta_file_or_dir = './my_FASTA_directory/', output_dir = './out', param = 'RaptorX-Single-ESM1b-ESM1v-ProtTrans-Ab.pt', device='cpu' ).run() The available model parameters are: 'RaptorX-Single-ESM1b.pt', 'RaptorX-Single-ESM1v.pt', 'RaptorX-Single-ProtTrans.pt', 'RaptorX-Single-ESM1b-ESM1v-ProtTrans.pt', 'RaptorX-Single-ESM1b-Ab.pt', 'RaptorX-Single-ESM1v-Ab.pt', 'RaptorX-Single-ProtTrans-Ab.pt', 'RaptorX-Single-ESM1b-ESM1v-ProtTrans-Ab.pt'","title":"Cookbook"},{"location":"cookbook/#cookbook","text":"Warning \ud83d\udea7 This page is under construction! We are still adding recipes for several Tasks . \ud83d\udea7","title":"Cookbook"},{"location":"cookbook/#chai-1","text":"Chai-1 is a high accuracy, ligand-aware protein folding tool. It takes as input a FASTA file, and outputs a directory of folded PDB structures. Chai-1 scores are output as .npz files.","title":"Chai-1"},{"location":"cookbook/#simple","text":"Fold a protein from a sequence ribbon.Chai1( fasta_file = 'my_sequence.fasta', # A single input FASTA. If there are multiple sequences, they will be folded in the same structure. output_dir = './out' # Where the outputs will be stored ).run()","title":"Simple"},{"location":"cookbook/#advanced","text":"Fold a protein from a sequence. Include two copies of ligand ribbon.Chai1( fasta_file = 'my_sequence.fasta', # A single input FASTA. If there are multiple sequences, they will be folded in the same structure. output_dir = './out', # Where the outputs will be stored smiles_string = 'C1=CC=CC=C1', # SMILES string of our ligand num_ligands = 2, # How many copies of our ligand? device = 'gpu' # Run on GPU (necessary for Chai-1) ).run()","title":"Advanced"},{"location":"cookbook/#ligandmpnn","text":"LigandMPNN is a ligand-aware tool for designing sequences for a backbone structure. It takes as input a list of PDB files, and outputs a sequence (or sequences) that are predicted to fold into that structure. While LigandMPNN is gpu-accelerated, it seems to run fast on the CPU as well.","title":"LigandMPNN"},{"location":"cookbook/#simple_1","text":"Design a sequence for a backbone: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], # List of PDB files output_dir = './out' # Output directory num_designs = 5 # How many sequences should we generate? ).run() The output folder will have the following structure: output_dir/ \u251c\u2500 backbones/ # Backbone structures with labeled AAs (but no sidechains) \u251c\u2500 packed/ # (Optional) Backbone structures with packed sidechains \u251c\u2500 seqs/ # A single FASTA containing the reference sequence and all designed sequences \u2514\u2500 seqs_split/ # Individual FASTA files for each designed sequence","title":"Simple"},{"location":"cookbook/#advanced_1","text":"Design a homodimeric sequence, keeping crucial residues fixed. This example uses the extra_args parameter to add extra parameters into your run command. Note that this can inject arbitrary code into your container - use with caution! ligandmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], # List of PDB files output_dir = './out' # Output directory num_designs = 5 # How many sequences should we generate? extra_args= '--fixed_residues \\\"' + RESIDUES_TO_KEEP + '\\\" --homo_oligomer 1' # Make sure to keep my catalytric residues, and make two chains identical. )","title":"Advanced"},{"location":"cookbook/#raptorx-single","text":"RaptorX-Single is a fast protein folding tool. It can fold small structures in as little as 5 seconds, after an initial loading period. It takes as input a FASTA file (or directory containing FASTAs), and outputs a directory of folded PDB structures.","title":"RaptorX-Single"},{"location":"cookbook/#simple_2","text":"Fold a directory of FASTA files ribbon.RaptorXSingle( fasta_file_or_dir = './my_FASTA_directory/', output_dir = './out' ).run()","title":"Simple"},{"location":"cookbook/#advanced_2","text":"Fold a directory of FASTA files using a non-default model checkpoint (param). Run on the CPU (slower; GPU is default). ribbon.RaptorXSingle( fasta_file_or_dir = './my_FASTA_directory/', output_dir = './out', param = 'RaptorX-Single-ESM1b-ESM1v-ProtTrans-Ab.pt', device='cpu' ).run() The available model parameters are: 'RaptorX-Single-ESM1b.pt', 'RaptorX-Single-ESM1v.pt', 'RaptorX-Single-ProtTrans.pt', 'RaptorX-Single-ESM1b-ESM1v-ProtTrans.pt', 'RaptorX-Single-ESM1b-Ab.pt', 'RaptorX-Single-ESM1v-Ab.pt', 'RaptorX-Single-ProtTrans-Ab.pt', 'RaptorX-Single-ESM1b-ESM1v-ProtTrans-Ab.pt'","title":"Advanced"},{"location":"design/","text":"Warning \ud83d\udea7 This Page is Under Construction! \ud83d\udea7","title":"Design Notes"},{"location":"installation/","text":"Installation Apptainer is the only requirement to run Ribbon. Install apptainer for your system here . We recommend creating a fresh environment for Ribbon: conda create --name ribbon python=3.12 -y conda activate ribbon Then, install Ribbon in a clean python environment: pip install ribbon-toolkit","title":"Installation"},{"location":"installation/#installation","text":"Apptainer is the only requirement to run Ribbon. Install apptainer for your system here . We recommend creating a fresh environment for Ribbon: conda create --name ribbon python=3.12 -y conda activate ribbon Then, install Ribbon in a clean python environment: pip install ribbon-toolkit","title":"Installation"},{"location":"api/config/","text":"get_data_directory () Return the directory where data files should reside. Source code in ribbon/config.py 38 39 40 41 42 43 44 def get_data_directory (): \"\"\"Return the directory where data files should reside.\"\"\" data_dir = os . environ . get ( RIBBON_TASKS_ENV_VAR , str ( DEFAULT_TASKS_DIR )) # double check - is it set to an empty string? if data_dir . strip () == \"\" : data_dir = str ( DEFAULT_TASKS_DIR ) return data_dir","title":"Config"},{"location":"api/config/#ribbon.config.get_data_directory","text":"Return the directory where data files should reside. Source code in ribbon/config.py 38 39 40 41 42 43 44 def get_data_directory (): \"\"\"Return the directory where data files should reside.\"\"\" data_dir = os . environ . get ( RIBBON_TASKS_ENV_VAR , str ( DEFAULT_TASKS_DIR )) # double check - is it set to an empty string? if data_dir . strip () == \"\" : data_dir = str ( DEFAULT_TASKS_DIR ) return data_dir","title":"get_data_directory"},{"location":"api/deserialize_and_run/","text":"","title":"Serialization"},{"location":"api/runner/","text":"Task Source code in ribbon/runner.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class Task : def __init__ ( self , device = 'cpu' , extra_args = \"\" ): \"\"\" The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Args: device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task Returns: None \"\"\" self . device = device self . extra_args = extra_args self . task_name = None def run ( self ): \"\"\" Run the task. This method should be overridden by the child class. \"\"\" raise NotImplementedError ( f \"You are attempting to run a task { self . __class__ . __name__ } without defining a run method.\" ) def queue ( self , scheduler , depends_on = [], dependency_type = 'afterok' , n_tasks = 1 , time = '1:00:00' , mem = '2G' , auto_restart = True , other_resources = {}, job_name = None , output_file = None , queue = None , gpus = None , node_name = None ): \"\"\" Queue the LigandMPNN task using the given scheduler. Args: scheduler (str): The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on (list, optional): A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type (str, optional): The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks (int, optional): The number of tasks to run. Defaults to 1. time (str, optional): The time to allocate for the task. Defaults to '1:00:00'. mem (str, optional): The memory to allocate for the task. Defaults to '2G'. auto_restart (bool, optional): Whether to automatically restart the task if it fails. Defaults to True. other_resources (dict, optional): Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name (str, optional): The name of the job. Defaults to None. output_file (str, optional): The file to write the output to. Defaults to None. queue (str, optional): The queue to submit the task to. Defaults to None. gpus (int, optional): The number of GPUs to allocate for the task. Defaults to None. node_name (str, optional): The name of the node to run the task on. Defaults to None. Returns: str: The ID of the job in the scheduler. \"\"\" # Serialize the task object to a pickle file: serialized_task = utils . serialize ( self ) # Retrieve the Ribbon container: ribbon_container_name = 'Ribbon' container_path = utils . verify_container ( ribbon_container_name ) # Retrieve the job's container: task_dict = self . _get_task_dict ( self . task_name ) job_container_name = task_dict [ 'container' ] utils . verify_container ( job_container_name ) # Correct the scheduler script mapping: MODULE_DIR = Path ( __file__ ) . resolve () . parent batch_script_dir = Path ( MODULE_DIR ) / 'batch' / 'batch_scripts' scheduler_script = { 'SLURM' : str ( batch_script_dir / 'slurm_submit.sh' ), 'SGE' : str ( batch_script_dir / 'sge_submit.sh' )}[ scheduler ] deserialize_script = Path ( MODULE_DIR ) / 'deserialize_and_run.py' # Prepare job variables: job_variables = f \"ribbon_container= { container_path } ,\" \\ f \"ribbon_deserialize_script= { deserialize_script } ,\" \\ f \"serialized_job= { serialized_task } ,\" \\ f \"RIBBON_TASKS_DIR= { os . getenv ( 'RIBBON_TASKS_DIR' ) } ,\" \\ f \"DEVICE= { self . device } \" ###################################### # Prepare the resources: # TODO: this is messy, we should clean this up later resources = { 'time' : time , 'mem' : mem } if depends_on : resources [ 'dependency' ] = depends_on if gpus : resources [ 'gpus' ] = gpus if job_name : resources [ 'job-name' ] = job_name if auto_restart : resources [ 'requeue' ] = True # Use True to indicate a flag without a value if output_file : resources [ 'output' ] = output_file if queue : resources [ 'queue' ] = queue if node_name : resources [ 'node-name' ] = node_name # Note: We don't parse other_resouces in the same way - we just pass them through as-is, # assuming the user has formatted them correctly. ######################################################### # Generate the command using queue_utils if scheduler == 'SLURM' : command = queue_utils . generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ) elif scheduler == 'SGE' : command = queue_utils . generate_sge_command ( resources , other_resources , job_variables , scheduler_script ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) # Run the task: stdout , stderr = utils . run_command ( command , capture_output = True ) print ( stdout , stderr ) # Parse the job ID from the output: if scheduler == 'SLURM' : job_id = queue_utils . parse_slurm_output ( stdout ) elif scheduler == 'SGE' : job_id = queue_utils . parse_sge_output ( stdout ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) return job_id def _run_task ( self , task_name , scheduler = 'local' , device = 'gpu' , extra_args = \"\" , container_override = None , ** kwargs ): \"\"\" Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Args: task_name (str): The name of the task to run. device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override (str, optional): The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs (dict): Task-specific keyword arguments. Returns: None \"\"\" # Add extra_args to kwargs: kwargs [ 'extra_args' ] = extra_args # Which inputs does our task require? required_inputs = self . _get_task_inputs ( task_name ) # Check that we have all the required inputs for input in required_inputs : if input not in kwargs : raise ValueError ( f 'Input { input } is required for task { task_name } ' ) # Get Information about the task: task_dict = self . _get_task_dict ( task_name ) task_name = task_dict [ 'name' ] container_name = task_dict [ 'container' ] # Allow user to override the default container (used for the Custom task): if container_override is not None : container_name = container_override print ( '--------------------------------------------' ) print ( '- Task name:' , task_name ) print ( '- Task description:' , task_dict [ 'description' ]) # Verify we have the container associated with the software we want to run. # If not, attempt to download it to the download_dir container_path = utils . verify_container ( container_name ) # Add inputs to the command, by replacing the placeholders in the command string: command = task_dict [ 'command' ] for input in required_inputs : command = command . replace ( f ' {{ { input } }} ' , str ( kwargs [ input ])) #We need three sets of braces. Two sets are needed to escape them, and the third set is the actual placeholder. print ( '- Command:' , command ) # Set nvidia flag: nvidia_flag = { 'gpu' : '--nv' , 'gpu_wsl' : '--nvccli' , 'cpu' : '' }[ device ] # Set user-provided environment variables: env_variables_string = '' if 'environment_variables' in task_dict : if len ( task_dict [ 'environment_variables' ]) > 0 : env_variables_string = '--env ' # Join each key-value pair with a comma: env_variables_string += ',' . join ([ f ' { key } = { value } ' for key , value in task_dict [ 'environment_variables' ] . items ()]) # Run the task apptainer_command = f 'apptainer run { nvidia_flag } { env_variables_string } { container_path } { command } ' utils . run_command ( apptainer_command ) print ( '--------------------------------------------' ) def _get_task_dict ( self , task_name ): \"\"\" Returns the dictionary for a given task. \"\"\" # Which inputs does our task require? with open ( TASKS_MODULE_DIR / 'tasks.json' ) as f : tasks = json . load ( f ) return tasks [ task_name ] def _get_task_inputs ( self , task_name ): \"\"\"Returns the inputs required for a given task\"\"\" # Get the command: command = self . _get_task_dict ( task_name )[ 'command' ] # Use regex to find all occurrences of text inside curly braces. # The pattern '\\{([^{}]+)\\}' matches a '{', then captures any characters except '{' or '}', then a '}'. inputs = re . findall ( r '\\{([^ {} ]+)\\}' , command ) # Remove duplicates: inputs = list ( set ( inputs )) return inputs def __repr__ ( self ): \"\"\" Returns a string representation of the Task object. \"\"\" return f \" { self . __class__ . __name__ } \\ { self . __dict__ } \" __init__ ( device = 'cpu' , extra_args = '' ) The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Parameters: device ( str , default: 'cpu' ) \u2013 Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args ( str , default: '' ) \u2013 Additional arguments to pass to the task Returns: \u2013 None Source code in ribbon/runner.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def __init__ ( self , device = 'cpu' , extra_args = \"\" ): \"\"\" The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Args: device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task Returns: None \"\"\" self . device = device self . extra_args = extra_args self . task_name = None __repr__ () Returns a string representation of the Task object. Source code in ribbon/runner.py 223 224 225 226 227 228 def __repr__ ( self ): \"\"\" Returns a string representation of the Task object. \"\"\" return f \" { self . __class__ . __name__ } \\ { self . __dict__ } \" _get_task_dict ( task_name ) Returns the dictionary for a given task. Source code in ribbon/runner.py 199 200 201 202 203 204 205 206 207 def _get_task_dict ( self , task_name ): \"\"\" Returns the dictionary for a given task. \"\"\" # Which inputs does our task require? with open ( TASKS_MODULE_DIR / 'tasks.json' ) as f : tasks = json . load ( f ) return tasks [ task_name ] _get_task_inputs ( task_name ) Returns the inputs required for a given task Source code in ribbon/runner.py 209 210 211 212 213 214 215 216 217 218 219 220 221 def _get_task_inputs ( self , task_name ): \"\"\"Returns the inputs required for a given task\"\"\" # Get the command: command = self . _get_task_dict ( task_name )[ 'command' ] # Use regex to find all occurrences of text inside curly braces. # The pattern '\\{([^{}]+)\\}' matches a '{', then captures any characters except '{' or '}', then a '}'. inputs = re . findall ( r '\\{([^ {} ]+)\\}' , command ) # Remove duplicates: inputs = list ( set ( inputs )) return inputs _run_task ( task_name , scheduler = 'local' , device = 'gpu' , extra_args = '' , container_override = None , ** kwargs ) Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Parameters: task_name ( str ) \u2013 The name of the task to run. device ( str , default: 'gpu' ) \u2013 Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args ( str , default: '' ) \u2013 Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override ( str , default: None ) \u2013 The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs ( dict , default: {} ) \u2013 Task-specific keyword arguments. Returns: \u2013 None Source code in ribbon/runner.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def _run_task ( self , task_name , scheduler = 'local' , device = 'gpu' , extra_args = \"\" , container_override = None , ** kwargs ): \"\"\" Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Args: task_name (str): The name of the task to run. device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override (str, optional): The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs (dict): Task-specific keyword arguments. Returns: None \"\"\" # Add extra_args to kwargs: kwargs [ 'extra_args' ] = extra_args # Which inputs does our task require? required_inputs = self . _get_task_inputs ( task_name ) # Check that we have all the required inputs for input in required_inputs : if input not in kwargs : raise ValueError ( f 'Input { input } is required for task { task_name } ' ) # Get Information about the task: task_dict = self . _get_task_dict ( task_name ) task_name = task_dict [ 'name' ] container_name = task_dict [ 'container' ] # Allow user to override the default container (used for the Custom task): if container_override is not None : container_name = container_override print ( '--------------------------------------------' ) print ( '- Task name:' , task_name ) print ( '- Task description:' , task_dict [ 'description' ]) # Verify we have the container associated with the software we want to run. # If not, attempt to download it to the download_dir container_path = utils . verify_container ( container_name ) # Add inputs to the command, by replacing the placeholders in the command string: command = task_dict [ 'command' ] for input in required_inputs : command = command . replace ( f ' {{ { input } }} ' , str ( kwargs [ input ])) #We need three sets of braces. Two sets are needed to escape them, and the third set is the actual placeholder. print ( '- Command:' , command ) # Set nvidia flag: nvidia_flag = { 'gpu' : '--nv' , 'gpu_wsl' : '--nvccli' , 'cpu' : '' }[ device ] # Set user-provided environment variables: env_variables_string = '' if 'environment_variables' in task_dict : if len ( task_dict [ 'environment_variables' ]) > 0 : env_variables_string = '--env ' # Join each key-value pair with a comma: env_variables_string += ',' . join ([ f ' { key } = { value } ' for key , value in task_dict [ 'environment_variables' ] . items ()]) # Run the task apptainer_command = f 'apptainer run { nvidia_flag } { env_variables_string } { container_path } { command } ' utils . run_command ( apptainer_command ) print ( '--------------------------------------------' ) queue ( scheduler , depends_on = [], dependency_type = 'afterok' , n_tasks = 1 , time = '1:00:00' , mem = '2G' , auto_restart = True , other_resources = {}, job_name = None , output_file = None , queue = None , gpus = None , node_name = None ) Queue the LigandMPNN task using the given scheduler. Parameters: scheduler ( str ) \u2013 The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on ( list , default: [] ) \u2013 A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type ( str , default: 'afterok' ) \u2013 The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks ( int , default: 1 ) \u2013 The number of tasks to run. Defaults to 1. time ( str , default: '1:00:00' ) \u2013 The time to allocate for the task. Defaults to '1:00:00'. mem ( str , default: '2G' ) \u2013 The memory to allocate for the task. Defaults to '2G'. auto_restart ( bool , default: True ) \u2013 Whether to automatically restart the task if it fails. Defaults to True. other_resources ( dict , default: {} ) \u2013 Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name ( str , default: None ) \u2013 The name of the job. Defaults to None. output_file ( str , default: None ) \u2013 The file to write the output to. Defaults to None. queue ( str , default: None ) \u2013 The queue to submit the task to. Defaults to None. gpus ( int , default: None ) \u2013 The number of GPUs to allocate for the task. Defaults to None. node_name ( str , default: None ) \u2013 The name of the node to run the task on. Defaults to None. Returns: str \u2013 The ID of the job in the scheduler. Source code in ribbon/runner.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def queue ( self , scheduler , depends_on = [], dependency_type = 'afterok' , n_tasks = 1 , time = '1:00:00' , mem = '2G' , auto_restart = True , other_resources = {}, job_name = None , output_file = None , queue = None , gpus = None , node_name = None ): \"\"\" Queue the LigandMPNN task using the given scheduler. Args: scheduler (str): The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on (list, optional): A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type (str, optional): The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks (int, optional): The number of tasks to run. Defaults to 1. time (str, optional): The time to allocate for the task. Defaults to '1:00:00'. mem (str, optional): The memory to allocate for the task. Defaults to '2G'. auto_restart (bool, optional): Whether to automatically restart the task if it fails. Defaults to True. other_resources (dict, optional): Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name (str, optional): The name of the job. Defaults to None. output_file (str, optional): The file to write the output to. Defaults to None. queue (str, optional): The queue to submit the task to. Defaults to None. gpus (int, optional): The number of GPUs to allocate for the task. Defaults to None. node_name (str, optional): The name of the node to run the task on. Defaults to None. Returns: str: The ID of the job in the scheduler. \"\"\" # Serialize the task object to a pickle file: serialized_task = utils . serialize ( self ) # Retrieve the Ribbon container: ribbon_container_name = 'Ribbon' container_path = utils . verify_container ( ribbon_container_name ) # Retrieve the job's container: task_dict = self . _get_task_dict ( self . task_name ) job_container_name = task_dict [ 'container' ] utils . verify_container ( job_container_name ) # Correct the scheduler script mapping: MODULE_DIR = Path ( __file__ ) . resolve () . parent batch_script_dir = Path ( MODULE_DIR ) / 'batch' / 'batch_scripts' scheduler_script = { 'SLURM' : str ( batch_script_dir / 'slurm_submit.sh' ), 'SGE' : str ( batch_script_dir / 'sge_submit.sh' )}[ scheduler ] deserialize_script = Path ( MODULE_DIR ) / 'deserialize_and_run.py' # Prepare job variables: job_variables = f \"ribbon_container= { container_path } ,\" \\ f \"ribbon_deserialize_script= { deserialize_script } ,\" \\ f \"serialized_job= { serialized_task } ,\" \\ f \"RIBBON_TASKS_DIR= { os . getenv ( 'RIBBON_TASKS_DIR' ) } ,\" \\ f \"DEVICE= { self . device } \" ###################################### # Prepare the resources: # TODO: this is messy, we should clean this up later resources = { 'time' : time , 'mem' : mem } if depends_on : resources [ 'dependency' ] = depends_on if gpus : resources [ 'gpus' ] = gpus if job_name : resources [ 'job-name' ] = job_name if auto_restart : resources [ 'requeue' ] = True # Use True to indicate a flag without a value if output_file : resources [ 'output' ] = output_file if queue : resources [ 'queue' ] = queue if node_name : resources [ 'node-name' ] = node_name # Note: We don't parse other_resouces in the same way - we just pass them through as-is, # assuming the user has formatted them correctly. ######################################################### # Generate the command using queue_utils if scheduler == 'SLURM' : command = queue_utils . generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ) elif scheduler == 'SGE' : command = queue_utils . generate_sge_command ( resources , other_resources , job_variables , scheduler_script ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) # Run the task: stdout , stderr = utils . run_command ( command , capture_output = True ) print ( stdout , stderr ) # Parse the job ID from the output: if scheduler == 'SLURM' : job_id = queue_utils . parse_slurm_output ( stdout ) elif scheduler == 'SGE' : job_id = queue_utils . parse_sge_output ( stdout ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) return job_id run () Run the task. This method should be overridden by the child class. Source code in ribbon/runner.py 26 27 28 29 30 def run ( self ): \"\"\" Run the task. This method should be overridden by the child class. \"\"\" raise NotImplementedError ( f \"You are attempting to run a task { self . __class__ . __name__ } without defining a run method.\" )","title":"Core Ribbon Task"},{"location":"api/runner/#ribbon.runner.Task","text":"Source code in ribbon/runner.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class Task : def __init__ ( self , device = 'cpu' , extra_args = \"\" ): \"\"\" The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Args: device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task Returns: None \"\"\" self . device = device self . extra_args = extra_args self . task_name = None def run ( self ): \"\"\" Run the task. This method should be overridden by the child class. \"\"\" raise NotImplementedError ( f \"You are attempting to run a task { self . __class__ . __name__ } without defining a run method.\" ) def queue ( self , scheduler , depends_on = [], dependency_type = 'afterok' , n_tasks = 1 , time = '1:00:00' , mem = '2G' , auto_restart = True , other_resources = {}, job_name = None , output_file = None , queue = None , gpus = None , node_name = None ): \"\"\" Queue the LigandMPNN task using the given scheduler. Args: scheduler (str): The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on (list, optional): A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type (str, optional): The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks (int, optional): The number of tasks to run. Defaults to 1. time (str, optional): The time to allocate for the task. Defaults to '1:00:00'. mem (str, optional): The memory to allocate for the task. Defaults to '2G'. auto_restart (bool, optional): Whether to automatically restart the task if it fails. Defaults to True. other_resources (dict, optional): Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name (str, optional): The name of the job. Defaults to None. output_file (str, optional): The file to write the output to. Defaults to None. queue (str, optional): The queue to submit the task to. Defaults to None. gpus (int, optional): The number of GPUs to allocate for the task. Defaults to None. node_name (str, optional): The name of the node to run the task on. Defaults to None. Returns: str: The ID of the job in the scheduler. \"\"\" # Serialize the task object to a pickle file: serialized_task = utils . serialize ( self ) # Retrieve the Ribbon container: ribbon_container_name = 'Ribbon' container_path = utils . verify_container ( ribbon_container_name ) # Retrieve the job's container: task_dict = self . _get_task_dict ( self . task_name ) job_container_name = task_dict [ 'container' ] utils . verify_container ( job_container_name ) # Correct the scheduler script mapping: MODULE_DIR = Path ( __file__ ) . resolve () . parent batch_script_dir = Path ( MODULE_DIR ) / 'batch' / 'batch_scripts' scheduler_script = { 'SLURM' : str ( batch_script_dir / 'slurm_submit.sh' ), 'SGE' : str ( batch_script_dir / 'sge_submit.sh' )}[ scheduler ] deserialize_script = Path ( MODULE_DIR ) / 'deserialize_and_run.py' # Prepare job variables: job_variables = f \"ribbon_container= { container_path } ,\" \\ f \"ribbon_deserialize_script= { deserialize_script } ,\" \\ f \"serialized_job= { serialized_task } ,\" \\ f \"RIBBON_TASKS_DIR= { os . getenv ( 'RIBBON_TASKS_DIR' ) } ,\" \\ f \"DEVICE= { self . device } \" ###################################### # Prepare the resources: # TODO: this is messy, we should clean this up later resources = { 'time' : time , 'mem' : mem } if depends_on : resources [ 'dependency' ] = depends_on if gpus : resources [ 'gpus' ] = gpus if job_name : resources [ 'job-name' ] = job_name if auto_restart : resources [ 'requeue' ] = True # Use True to indicate a flag without a value if output_file : resources [ 'output' ] = output_file if queue : resources [ 'queue' ] = queue if node_name : resources [ 'node-name' ] = node_name # Note: We don't parse other_resouces in the same way - we just pass them through as-is, # assuming the user has formatted them correctly. ######################################################### # Generate the command using queue_utils if scheduler == 'SLURM' : command = queue_utils . generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ) elif scheduler == 'SGE' : command = queue_utils . generate_sge_command ( resources , other_resources , job_variables , scheduler_script ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) # Run the task: stdout , stderr = utils . run_command ( command , capture_output = True ) print ( stdout , stderr ) # Parse the job ID from the output: if scheduler == 'SLURM' : job_id = queue_utils . parse_slurm_output ( stdout ) elif scheduler == 'SGE' : job_id = queue_utils . parse_sge_output ( stdout ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) return job_id def _run_task ( self , task_name , scheduler = 'local' , device = 'gpu' , extra_args = \"\" , container_override = None , ** kwargs ): \"\"\" Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Args: task_name (str): The name of the task to run. device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override (str, optional): The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs (dict): Task-specific keyword arguments. Returns: None \"\"\" # Add extra_args to kwargs: kwargs [ 'extra_args' ] = extra_args # Which inputs does our task require? required_inputs = self . _get_task_inputs ( task_name ) # Check that we have all the required inputs for input in required_inputs : if input not in kwargs : raise ValueError ( f 'Input { input } is required for task { task_name } ' ) # Get Information about the task: task_dict = self . _get_task_dict ( task_name ) task_name = task_dict [ 'name' ] container_name = task_dict [ 'container' ] # Allow user to override the default container (used for the Custom task): if container_override is not None : container_name = container_override print ( '--------------------------------------------' ) print ( '- Task name:' , task_name ) print ( '- Task description:' , task_dict [ 'description' ]) # Verify we have the container associated with the software we want to run. # If not, attempt to download it to the download_dir container_path = utils . verify_container ( container_name ) # Add inputs to the command, by replacing the placeholders in the command string: command = task_dict [ 'command' ] for input in required_inputs : command = command . replace ( f ' {{ { input } }} ' , str ( kwargs [ input ])) #We need three sets of braces. Two sets are needed to escape them, and the third set is the actual placeholder. print ( '- Command:' , command ) # Set nvidia flag: nvidia_flag = { 'gpu' : '--nv' , 'gpu_wsl' : '--nvccli' , 'cpu' : '' }[ device ] # Set user-provided environment variables: env_variables_string = '' if 'environment_variables' in task_dict : if len ( task_dict [ 'environment_variables' ]) > 0 : env_variables_string = '--env ' # Join each key-value pair with a comma: env_variables_string += ',' . join ([ f ' { key } = { value } ' for key , value in task_dict [ 'environment_variables' ] . items ()]) # Run the task apptainer_command = f 'apptainer run { nvidia_flag } { env_variables_string } { container_path } { command } ' utils . run_command ( apptainer_command ) print ( '--------------------------------------------' ) def _get_task_dict ( self , task_name ): \"\"\" Returns the dictionary for a given task. \"\"\" # Which inputs does our task require? with open ( TASKS_MODULE_DIR / 'tasks.json' ) as f : tasks = json . load ( f ) return tasks [ task_name ] def _get_task_inputs ( self , task_name ): \"\"\"Returns the inputs required for a given task\"\"\" # Get the command: command = self . _get_task_dict ( task_name )[ 'command' ] # Use regex to find all occurrences of text inside curly braces. # The pattern '\\{([^{}]+)\\}' matches a '{', then captures any characters except '{' or '}', then a '}'. inputs = re . findall ( r '\\{([^ {} ]+)\\}' , command ) # Remove duplicates: inputs = list ( set ( inputs )) return inputs def __repr__ ( self ): \"\"\" Returns a string representation of the Task object. \"\"\" return f \" { self . __class__ . __name__ } \\ { self . __dict__ } \"","title":"Task"},{"location":"api/runner/#ribbon.runner.Task.__init__","text":"The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Parameters: device ( str , default: 'cpu' ) \u2013 Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args ( str , default: '' ) \u2013 Additional arguments to pass to the task Returns: \u2013 None Source code in ribbon/runner.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def __init__ ( self , device = 'cpu' , extra_args = \"\" ): \"\"\" The Task class is the parent class for all tasks in the Ribbon framework. It contains the basic functionality for running tasks, queuing tasks, and managing task dependencies. Args: device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task Returns: None \"\"\" self . device = device self . extra_args = extra_args self . task_name = None","title":"__init__"},{"location":"api/runner/#ribbon.runner.Task.__repr__","text":"Returns a string representation of the Task object. Source code in ribbon/runner.py 223 224 225 226 227 228 def __repr__ ( self ): \"\"\" Returns a string representation of the Task object. \"\"\" return f \" { self . __class__ . __name__ } \\ { self . __dict__ } \"","title":"__repr__"},{"location":"api/runner/#ribbon.runner.Task._get_task_dict","text":"Returns the dictionary for a given task. Source code in ribbon/runner.py 199 200 201 202 203 204 205 206 207 def _get_task_dict ( self , task_name ): \"\"\" Returns the dictionary for a given task. \"\"\" # Which inputs does our task require? with open ( TASKS_MODULE_DIR / 'tasks.json' ) as f : tasks = json . load ( f ) return tasks [ task_name ]","title":"_get_task_dict"},{"location":"api/runner/#ribbon.runner.Task._get_task_inputs","text":"Returns the inputs required for a given task Source code in ribbon/runner.py 209 210 211 212 213 214 215 216 217 218 219 220 221 def _get_task_inputs ( self , task_name ): \"\"\"Returns the inputs required for a given task\"\"\" # Get the command: command = self . _get_task_dict ( task_name )[ 'command' ] # Use regex to find all occurrences of text inside curly braces. # The pattern '\\{([^{}]+)\\}' matches a '{', then captures any characters except '{' or '}', then a '}'. inputs = re . findall ( r '\\{([^ {} ]+)\\}' , command ) # Remove duplicates: inputs = list ( set ( inputs )) return inputs","title":"_get_task_inputs"},{"location":"api/runner/#ribbon.runner.Task._run_task","text":"Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Parameters: task_name ( str ) \u2013 The name of the task to run. device ( str , default: 'gpu' ) \u2013 Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args ( str , default: '' ) \u2013 Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override ( str , default: None ) \u2013 The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs ( dict , default: {} ) \u2013 Task-specific keyword arguments. Returns: \u2013 None Source code in ribbon/runner.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def _run_task ( self , task_name , scheduler = 'local' , device = 'gpu' , extra_args = \"\" , container_override = None , ** kwargs ): \"\"\" Run a task with the given name and arguments. In the child Task class, this method should be called from within the user-facing run() method. Args: task_name (str): The name of the task to run. device (str): Enables Apptainer to use GPU. Options are 'gpu', 'gpu_wsl' (if using WSL), or 'cpu'. Default is 'gpu'. extra_args (str, optional): Additional arguments to pass to the task, e.g. '--save_frequency 10 --num_steps 1000'. container_override (str, optional): The name of the container to use for the task. If not provided, the default container for that Task will be used. kwargs (dict): Task-specific keyword arguments. Returns: None \"\"\" # Add extra_args to kwargs: kwargs [ 'extra_args' ] = extra_args # Which inputs does our task require? required_inputs = self . _get_task_inputs ( task_name ) # Check that we have all the required inputs for input in required_inputs : if input not in kwargs : raise ValueError ( f 'Input { input } is required for task { task_name } ' ) # Get Information about the task: task_dict = self . _get_task_dict ( task_name ) task_name = task_dict [ 'name' ] container_name = task_dict [ 'container' ] # Allow user to override the default container (used for the Custom task): if container_override is not None : container_name = container_override print ( '--------------------------------------------' ) print ( '- Task name:' , task_name ) print ( '- Task description:' , task_dict [ 'description' ]) # Verify we have the container associated with the software we want to run. # If not, attempt to download it to the download_dir container_path = utils . verify_container ( container_name ) # Add inputs to the command, by replacing the placeholders in the command string: command = task_dict [ 'command' ] for input in required_inputs : command = command . replace ( f ' {{ { input } }} ' , str ( kwargs [ input ])) #We need three sets of braces. Two sets are needed to escape them, and the third set is the actual placeholder. print ( '- Command:' , command ) # Set nvidia flag: nvidia_flag = { 'gpu' : '--nv' , 'gpu_wsl' : '--nvccli' , 'cpu' : '' }[ device ] # Set user-provided environment variables: env_variables_string = '' if 'environment_variables' in task_dict : if len ( task_dict [ 'environment_variables' ]) > 0 : env_variables_string = '--env ' # Join each key-value pair with a comma: env_variables_string += ',' . join ([ f ' { key } = { value } ' for key , value in task_dict [ 'environment_variables' ] . items ()]) # Run the task apptainer_command = f 'apptainer run { nvidia_flag } { env_variables_string } { container_path } { command } ' utils . run_command ( apptainer_command ) print ( '--------------------------------------------' )","title":"_run_task"},{"location":"api/runner/#ribbon.runner.Task.queue","text":"Queue the LigandMPNN task using the given scheduler. Parameters: scheduler ( str ) \u2013 The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on ( list , default: [] ) \u2013 A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type ( str , default: 'afterok' ) \u2013 The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks ( int , default: 1 ) \u2013 The number of tasks to run. Defaults to 1. time ( str , default: '1:00:00' ) \u2013 The time to allocate for the task. Defaults to '1:00:00'. mem ( str , default: '2G' ) \u2013 The memory to allocate for the task. Defaults to '2G'. auto_restart ( bool , default: True ) \u2013 Whether to automatically restart the task if it fails. Defaults to True. other_resources ( dict , default: {} ) \u2013 Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name ( str , default: None ) \u2013 The name of the job. Defaults to None. output_file ( str , default: None ) \u2013 The file to write the output to. Defaults to None. queue ( str , default: None ) \u2013 The queue to submit the task to. Defaults to None. gpus ( int , default: None ) \u2013 The number of GPUs to allocate for the task. Defaults to None. node_name ( str , default: None ) \u2013 The name of the node to run the task on. Defaults to None. Returns: str \u2013 The ID of the job in the scheduler. Source code in ribbon/runner.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def queue ( self , scheduler , depends_on = [], dependency_type = 'afterok' , n_tasks = 1 , time = '1:00:00' , mem = '2G' , auto_restart = True , other_resources = {}, job_name = None , output_file = None , queue = None , gpus = None , node_name = None ): \"\"\" Queue the LigandMPNN task using the given scheduler. Args: scheduler (str): The name of the scheduler to use. Options are 'SLURM' or 'SGE'. depends_on (list, optional): A jobID or list of jobIDs that this job depends on. (Each is an int or str). Defaults to []. dependency_type (str, optional): The type of dependency. Options are 'afterok', 'afternotok', 'afterany', 'after', 'singleton'. Defaults to 'afterok'. n_tasks (int, optional): The number of tasks to run. Defaults to 1. time (str, optional): The time to allocate for the task. Defaults to '1:00:00'. mem (str, optional): The memory to allocate for the task. Defaults to '2G'. auto_restart (bool, optional): Whether to automatically restart the task if it fails. Defaults to True. other_resources (dict, optional): Other resources to allocate for the task. Has the form {\"--option\": \"value\"}. Defaults to {}. job_name (str, optional): The name of the job. Defaults to None. output_file (str, optional): The file to write the output to. Defaults to None. queue (str, optional): The queue to submit the task to. Defaults to None. gpus (int, optional): The number of GPUs to allocate for the task. Defaults to None. node_name (str, optional): The name of the node to run the task on. Defaults to None. Returns: str: The ID of the job in the scheduler. \"\"\" # Serialize the task object to a pickle file: serialized_task = utils . serialize ( self ) # Retrieve the Ribbon container: ribbon_container_name = 'Ribbon' container_path = utils . verify_container ( ribbon_container_name ) # Retrieve the job's container: task_dict = self . _get_task_dict ( self . task_name ) job_container_name = task_dict [ 'container' ] utils . verify_container ( job_container_name ) # Correct the scheduler script mapping: MODULE_DIR = Path ( __file__ ) . resolve () . parent batch_script_dir = Path ( MODULE_DIR ) / 'batch' / 'batch_scripts' scheduler_script = { 'SLURM' : str ( batch_script_dir / 'slurm_submit.sh' ), 'SGE' : str ( batch_script_dir / 'sge_submit.sh' )}[ scheduler ] deserialize_script = Path ( MODULE_DIR ) / 'deserialize_and_run.py' # Prepare job variables: job_variables = f \"ribbon_container= { container_path } ,\" \\ f \"ribbon_deserialize_script= { deserialize_script } ,\" \\ f \"serialized_job= { serialized_task } ,\" \\ f \"RIBBON_TASKS_DIR= { os . getenv ( 'RIBBON_TASKS_DIR' ) } ,\" \\ f \"DEVICE= { self . device } \" ###################################### # Prepare the resources: # TODO: this is messy, we should clean this up later resources = { 'time' : time , 'mem' : mem } if depends_on : resources [ 'dependency' ] = depends_on if gpus : resources [ 'gpus' ] = gpus if job_name : resources [ 'job-name' ] = job_name if auto_restart : resources [ 'requeue' ] = True # Use True to indicate a flag without a value if output_file : resources [ 'output' ] = output_file if queue : resources [ 'queue' ] = queue if node_name : resources [ 'node-name' ] = node_name # Note: We don't parse other_resouces in the same way - we just pass them through as-is, # assuming the user has formatted them correctly. ######################################################### # Generate the command using queue_utils if scheduler == 'SLURM' : command = queue_utils . generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ) elif scheduler == 'SGE' : command = queue_utils . generate_sge_command ( resources , other_resources , job_variables , scheduler_script ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) # Run the task: stdout , stderr = utils . run_command ( command , capture_output = True ) print ( stdout , stderr ) # Parse the job ID from the output: if scheduler == 'SLURM' : job_id = queue_utils . parse_slurm_output ( stdout ) elif scheduler == 'SGE' : job_id = queue_utils . parse_sge_output ( stdout ) else : raise ValueError ( f \"Unsupported scheduler: { scheduler } \" ) return job_id","title":"queue"},{"location":"api/runner/#ribbon.runner.Task.run","text":"Run the task. This method should be overridden by the child class. Source code in ribbon/runner.py 26 27 28 29 30 def run ( self ): \"\"\" Run the task. This method should be overridden by the child class. \"\"\" raise NotImplementedError ( f \"You are attempting to run a task { self . __class__ . __name__ } without defining a run method.\" )","title":"run"},{"location":"api/utils/","text":"clean_cache ( all = False ) Cleans the cache directory. If all=True, deletes all files. Otherwise, deletes only files that are older than 1 day. Source code in ribbon/utils.py 160 161 162 163 164 165 166 167 168 def clean_cache ( all = False ): \"\"\" Cleans the cache directory. If all=True, deletes all files. Otherwise, deletes only files that are older than 1 day. \"\"\" for file in os . listdir ( TASK_CACHE_DIR ): file = Path ( file ) if all or ( datetime . datetime . now () - datetime . datetime . fromtimestamp ( file . stat () . st_mtime )) . days > 1 : os . remove ( file ) deserialize ( filename , cache_dir = None ) Loads a Python object from a file. Parameters: filename \u2013 the filename to load the object from. cache_dir \u2013 the directory to load the object from. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: object \u2013 the Python object loaded from the file. Source code in ribbon/utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def deserialize ( filename , cache_dir = None ): \"\"\"Loads a Python object from a file. Args: filename: the filename to load the object from. cache_dir: the directory to load the object from. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: object: the Python object loaded from the file. \"\"\" # Make sure we have the full path: if cache_dir is None : cache_dir = TASK_CACHE_DIR cache_dir = make_directory ( cache_dir ) filename = Path ( filename ) if not filename . is_absolute (): filename = cache_dir / filename with open ( filename , 'rb' ) as f : return pickle . load ( f ) download_container ( container_local_path , container_ORAS_URL ) Downloads a container to the download directory, DOWNLOAD_DIR, from ribbon.config. Parameters: container_local_path ( str ) \u2013 The path to the container to download. container_ORAS_URL ( str ) \u2013 The ORAS URL of the container to download. Returns: \u2013 None Source code in ribbon/utils.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def download_container ( container_local_path , container_ORAS_URL ): \"\"\" Downloads a container to the download directory, DOWNLOAD_DIR, from ribbon.config. Args: container_local_path (str): The path to the container to download. container_ORAS_URL (str): The ORAS URL of the container to download. Returns: None \"\"\" # Make sure downloads directory exists: make_directories ( DOWNLOAD_DIR ) # Download the container to the download_dir command = f 'apptainer pull { container_local_path } { container_ORAS_URL } ' run_command ( command ) return # Get error codes, etc. list_files ( directory , extension ) Returns a list of files in a directory with a given extension Source code in ribbon/utils.py 15 16 17 def list_files ( directory , extension ): \"\"\"Returns a list of files in a directory with a given extension\"\"\" return [ os . path . join ( directory , f ) for f in os . listdir ( directory ) if f . endswith ( extension )] make_directories ( * directories ) Creates directories if they do not exist. Returns a list of Path objects, in case they were strings. Source code in ribbon/utils.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def make_directories ( * directories ): \"\"\" Creates directories if they do not exist. Returns a list of Path objects, in case they were strings. \"\"\" new_directories = [] for directory in directories : # Check it's a Path object: if not isinstance ( directory , Path ): directory = Path ( directory ) directory . mkdir ( parents = True , exist_ok = True ) new_directories . append ( directory ) return new_directories make_directory ( directory ) Creates a directory if it does not exist. Parameters: directory ( str or Path ) \u2013 The directory to create. Returns: Path \u2013 path object of the created directory. Source code in ribbon/utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 def make_directory ( directory ): \"\"\" Creates a directory if it does not exist. Args: directory (str or Path): The directory to create. Returns: Path: path object of the created directory. \"\"\" directory = make_directories ( directory )[ 0 ] return directory run_command ( command , capture_output = False ) Runs a command in the shell. If capture_output=True, returns the stdout and stderr. Otherwise, returns prints the stdout and stderr. Source code in ribbon/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def run_command ( command , capture_output = False ): \"\"\" Runs a command in the shell. If capture_output=True, returns the stdout and stderr. Otherwise, returns prints the stdout and stderr. \"\"\" # Run the container stdout , stderr = None , None print ( 'Running command:' , command ) if capture_output : process = subprocess . run ( command , shell = True , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # return stdout and stderr stdout , stderr = process . stdout . decode ( 'utf-8' ), process . stderr . decode ( 'utf-8' ) else : process = subprocess . run ( command , shell = True ) return stdout , stderr serialize ( obj , save_dir = None ) Saves a Python object to a file. A random filename is generated, and it is saved to the save_dir. Parameters: obj \u2013 the Python object to save. save_dir \u2013 the directory to save the object. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: Path \u2013 path object of the saved file. Source code in ribbon/utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def serialize ( obj , save_dir = None ): \"\"\"Saves a Python object to a file. A random filename is generated, and it is saved to the save_dir. Args: obj: the Python object to save. save_dir: the directory to save the object. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: Path: path object of the saved file. \"\"\" if save_dir is None : save_dir = TASK_CACHE_DIR # Make sure the directory exists: save_dir = make_directory ( save_dir ) print ( 'Saving object to:' , save_dir ) # Generate a random filename: filename = save_dir / f ' { uuid . uuid4 () } .pkl' # Save the object: with open ( filename , 'wb' ) as f : pickle . dump ( obj , f ) return filename verify_container ( software_name ) Verifies that the container for the given software is downloaded. If not, downloads it to DOWNLOAD_DIR from ribbon.config. Parameters: software_name ( str ) \u2013 The name of the software to verify the container for. Returns: str \u2013 The path to the downloaded container. Source code in ribbon/utils.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def verify_container ( software_name ): \"\"\" Verifies that the container for the given software is downloaded. If not, downloads it to DOWNLOAD_DIR from ribbon.config. Args: software_name (str): The name of the software to verify the container for. Returns: str: The path to the downloaded container. \"\"\" # Get the container local path and ORAS URL: import json with open ( TASKS_MODULE_DIR / 'containers.json' ) as f : containers = json . load ( f ) # Our database maps software names to container names and ORAS URLs # Example: {\"LigandMPNN\": [\"ligandMPNN.sif\", \"oras://docker.io/nicholasfreitas/ligandmpnn:latest\"]} container_local_name , container_ORAS_URL = containers [ software_name ] container_local_path = DOWNLOAD_DIR / container_local_name # Is the container already downloaded? if not os . path . exists ( container_local_path ): # If not, download the container download_container ( container_local_path , container_ORAS_URL ) return container_local_path wait_for_jobs ( job_ids , scheduler , max_wait = 3600 ) Waits for a list of job IDs to complete. Returns when all jobs are completed, or when max_wait is exceeded. Parameters: job_ids ( list ) \u2013 list of job IDs scheduler ( str ) \u2013 the scheduler to use. SGE or SLURM. max_wait ( int , default: 3600 ) \u2013 maximum time to wait in seconds. Default is 1 hour. Returns: \u2013 None TODO: Add kill_after parameter to kill jobs if we exceed max_wait. Default false. Source code in ribbon/utils.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def wait_for_jobs ( job_ids , scheduler , max_wait = 3600 ): \"\"\" Waits for a list of job IDs to complete. Returns when all jobs are completed, or when max_wait is exceeded. Args: job_ids (list): list of job IDs scheduler (str): the scheduler to use. SGE or SLURM. max_wait (int): maximum time to wait in seconds. Default is 1 hour. Returns: None TODO: Add kill_after parameter to kill jobs if we exceed max_wait. Default false. \"\"\" start_time = datetime . datetime . now () if scheduler == 'SGE' : check_job_status = sge_check_job_status elif scheduler == 'SLURM' : check_job_status = slurm_check_job_status else : raise ValueError ( 'Invalid scheduler. Must be SGE or SLURM.' ) # Print status: waiting_for = len ( job_ids ) print ( f 'Waiting for { waiting_for } jobs to complete...' ) while True : # Check if all jobs are completed: all_completed = True not_finished_count = 0 statuses = check_job_status ( job_ids ) for job_id , status in statuses . items (): if status == 'not completed' : all_completed = False not_finished_count += 1 if all_completed : break # All jobs are completed, we're done! # Print status, only when it changes: if not_finished_count != waiting_for : waiting_for = not_finished_count print ( f 'Waiting for { waiting_for } jobs to complete...' ) # Check if we've waited too long: elapsed_time = ( datetime . datetime . now () - start_time ) . seconds if elapsed_time > max_wait : print ( 'Max wait time exceeded. Exiting.' ) break # Wait for a bit before checking again: time . sleep ( 10 ) return","title":"Utils"},{"location":"api/utils/#ribbon.utils.clean_cache","text":"Cleans the cache directory. If all=True, deletes all files. Otherwise, deletes only files that are older than 1 day. Source code in ribbon/utils.py 160 161 162 163 164 165 166 167 168 def clean_cache ( all = False ): \"\"\" Cleans the cache directory. If all=True, deletes all files. Otherwise, deletes only files that are older than 1 day. \"\"\" for file in os . listdir ( TASK_CACHE_DIR ): file = Path ( file ) if all or ( datetime . datetime . now () - datetime . datetime . fromtimestamp ( file . stat () . st_mtime )) . days > 1 : os . remove ( file )","title":"clean_cache"},{"location":"api/utils/#ribbon.utils.deserialize","text":"Loads a Python object from a file. Parameters: filename \u2013 the filename to load the object from. cache_dir \u2013 the directory to load the object from. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: object \u2013 the Python object loaded from the file. Source code in ribbon/utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def deserialize ( filename , cache_dir = None ): \"\"\"Loads a Python object from a file. Args: filename: the filename to load the object from. cache_dir: the directory to load the object from. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: object: the Python object loaded from the file. \"\"\" # Make sure we have the full path: if cache_dir is None : cache_dir = TASK_CACHE_DIR cache_dir = make_directory ( cache_dir ) filename = Path ( filename ) if not filename . is_absolute (): filename = cache_dir / filename with open ( filename , 'rb' ) as f : return pickle . load ( f )","title":"deserialize"},{"location":"api/utils/#ribbon.utils.download_container","text":"Downloads a container to the download directory, DOWNLOAD_DIR, from ribbon.config. Parameters: container_local_path ( str ) \u2013 The path to the container to download. container_ORAS_URL ( str ) \u2013 The ORAS URL of the container to download. Returns: \u2013 None Source code in ribbon/utils.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def download_container ( container_local_path , container_ORAS_URL ): \"\"\" Downloads a container to the download directory, DOWNLOAD_DIR, from ribbon.config. Args: container_local_path (str): The path to the container to download. container_ORAS_URL (str): The ORAS URL of the container to download. Returns: None \"\"\" # Make sure downloads directory exists: make_directories ( DOWNLOAD_DIR ) # Download the container to the download_dir command = f 'apptainer pull { container_local_path } { container_ORAS_URL } ' run_command ( command ) return # Get error codes, etc.","title":"download_container"},{"location":"api/utils/#ribbon.utils.list_files","text":"Returns a list of files in a directory with a given extension Source code in ribbon/utils.py 15 16 17 def list_files ( directory , extension ): \"\"\"Returns a list of files in a directory with a given extension\"\"\" return [ os . path . join ( directory , f ) for f in os . listdir ( directory ) if f . endswith ( extension )]","title":"list_files"},{"location":"api/utils/#ribbon.utils.make_directories","text":"Creates directories if they do not exist. Returns a list of Path objects, in case they were strings. Source code in ribbon/utils.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def make_directories ( * directories ): \"\"\" Creates directories if they do not exist. Returns a list of Path objects, in case they were strings. \"\"\" new_directories = [] for directory in directories : # Check it's a Path object: if not isinstance ( directory , Path ): directory = Path ( directory ) directory . mkdir ( parents = True , exist_ok = True ) new_directories . append ( directory ) return new_directories","title":"make_directories"},{"location":"api/utils/#ribbon.utils.make_directory","text":"Creates a directory if it does not exist. Parameters: directory ( str or Path ) \u2013 The directory to create. Returns: Path \u2013 path object of the created directory. Source code in ribbon/utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 def make_directory ( directory ): \"\"\" Creates a directory if it does not exist. Args: directory (str or Path): The directory to create. Returns: Path: path object of the created directory. \"\"\" directory = make_directories ( directory )[ 0 ] return directory","title":"make_directory"},{"location":"api/utils/#ribbon.utils.run_command","text":"Runs a command in the shell. If capture_output=True, returns the stdout and stderr. Otherwise, returns prints the stdout and stderr. Source code in ribbon/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def run_command ( command , capture_output = False ): \"\"\" Runs a command in the shell. If capture_output=True, returns the stdout and stderr. Otherwise, returns prints the stdout and stderr. \"\"\" # Run the container stdout , stderr = None , None print ( 'Running command:' , command ) if capture_output : process = subprocess . run ( command , shell = True , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # return stdout and stderr stdout , stderr = process . stdout . decode ( 'utf-8' ), process . stderr . decode ( 'utf-8' ) else : process = subprocess . run ( command , shell = True ) return stdout , stderr","title":"run_command"},{"location":"api/utils/#ribbon.utils.serialize","text":"Saves a Python object to a file. A random filename is generated, and it is saved to the save_dir. Parameters: obj \u2013 the Python object to save. save_dir \u2013 the directory to save the object. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: Path \u2013 path object of the saved file. Source code in ribbon/utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def serialize ( obj , save_dir = None ): \"\"\"Saves a Python object to a file. A random filename is generated, and it is saved to the save_dir. Args: obj: the Python object to save. save_dir: the directory to save the object. If None, uses TASK_CACHE_DIR from ribbon.config. Returns: Path: path object of the saved file. \"\"\" if save_dir is None : save_dir = TASK_CACHE_DIR # Make sure the directory exists: save_dir = make_directory ( save_dir ) print ( 'Saving object to:' , save_dir ) # Generate a random filename: filename = save_dir / f ' { uuid . uuid4 () } .pkl' # Save the object: with open ( filename , 'wb' ) as f : pickle . dump ( obj , f ) return filename","title":"serialize"},{"location":"api/utils/#ribbon.utils.verify_container","text":"Verifies that the container for the given software is downloaded. If not, downloads it to DOWNLOAD_DIR from ribbon.config. Parameters: software_name ( str ) \u2013 The name of the software to verify the container for. Returns: str \u2013 The path to the downloaded container. Source code in ribbon/utils.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def verify_container ( software_name ): \"\"\" Verifies that the container for the given software is downloaded. If not, downloads it to DOWNLOAD_DIR from ribbon.config. Args: software_name (str): The name of the software to verify the container for. Returns: str: The path to the downloaded container. \"\"\" # Get the container local path and ORAS URL: import json with open ( TASKS_MODULE_DIR / 'containers.json' ) as f : containers = json . load ( f ) # Our database maps software names to container names and ORAS URLs # Example: {\"LigandMPNN\": [\"ligandMPNN.sif\", \"oras://docker.io/nicholasfreitas/ligandmpnn:latest\"]} container_local_name , container_ORAS_URL = containers [ software_name ] container_local_path = DOWNLOAD_DIR / container_local_name # Is the container already downloaded? if not os . path . exists ( container_local_path ): # If not, download the container download_container ( container_local_path , container_ORAS_URL ) return container_local_path","title":"verify_container"},{"location":"api/utils/#ribbon.utils.wait_for_jobs","text":"Waits for a list of job IDs to complete. Returns when all jobs are completed, or when max_wait is exceeded. Parameters: job_ids ( list ) \u2013 list of job IDs scheduler ( str ) \u2013 the scheduler to use. SGE or SLURM. max_wait ( int , default: 3600 ) \u2013 maximum time to wait in seconds. Default is 1 hour. Returns: \u2013 None TODO: Add kill_after parameter to kill jobs if we exceed max_wait. Default false. Source code in ribbon/utils.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def wait_for_jobs ( job_ids , scheduler , max_wait = 3600 ): \"\"\" Waits for a list of job IDs to complete. Returns when all jobs are completed, or when max_wait is exceeded. Args: job_ids (list): list of job IDs scheduler (str): the scheduler to use. SGE or SLURM. max_wait (int): maximum time to wait in seconds. Default is 1 hour. Returns: None TODO: Add kill_after parameter to kill jobs if we exceed max_wait. Default false. \"\"\" start_time = datetime . datetime . now () if scheduler == 'SGE' : check_job_status = sge_check_job_status elif scheduler == 'SLURM' : check_job_status = slurm_check_job_status else : raise ValueError ( 'Invalid scheduler. Must be SGE or SLURM.' ) # Print status: waiting_for = len ( job_ids ) print ( f 'Waiting for { waiting_for } jobs to complete...' ) while True : # Check if all jobs are completed: all_completed = True not_finished_count = 0 statuses = check_job_status ( job_ids ) for job_id , status in statuses . items (): if status == 'not completed' : all_completed = False not_finished_count += 1 if all_completed : break # All jobs are completed, we're done! # Print status, only when it changes: if not_finished_count != waiting_for : waiting_for = not_finished_count print ( f 'Waiting for { waiting_for } jobs to complete...' ) # Check if we've waited too long: elapsed_time = ( datetime . datetime . now () - start_time ) . seconds if elapsed_time > max_wait : print ( 'Max wait time exceeded. Exiting.' ) break # Wait for a bit before checking again: time . sleep ( 10 ) return","title":"wait_for_jobs"},{"location":"api/batch/batch/","text":"generate_sge_command ( resources , other_resources , job_variables , scheduler_script ) Generate an SGE command to submit a job to the scheduler. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. other_resources ( dict ) \u2013 A dictionary of other resources to pass to the scheduler. job_variables ( str ) \u2013 A string of environment variables to pass to the job. scheduler_script ( str ) \u2013 The path to the script to run. Returns: str \u2013 The SGE command to submit Source code in ribbon/batch/queue_utils.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def generate_sge_command ( resources , other_resources , job_variables , scheduler_script ): \"\"\" Generate an SGE command to submit a job to the scheduler. Args: resources (dict): A dictionary of resources to request for the job. other_resources (dict): A dictionary of other resources to pass to the scheduler. job_variables (str): A string of environment variables to pass to the job. scheduler_script (str): The path to the script to run. Returns: str: The SGE command to submit \"\"\" scheduler_command = 'qsub' # Map resources to SGE options resources_string = parse_sge_resources ( resources ) # Add other resources as-is, from dict: for key , value in other_resources . items (): if value == '' : # If value is empty, assume it's a flag without a value resources_string += f \" { key } \" else : if key . startswith ( '-l' ): resources_string += f \" { key } = { value } \" else : resources_string += f \" { key } { value } \" # Construct the command command = f \" { scheduler_command } -v { job_variables } { resources_string } { scheduler_script } \" return command generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ) Generate a SLURM command to submit a job to the scheduler. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. other_resources ( dict ) \u2013 A dictionary of other resources to pass to the scheduler. job_variables ( str ) \u2013 A string of environment variables to pass to the job. scheduler_script ( str ) \u2013 The path to the script to run. Returns: str \u2013 The SLURM command to submit Source code in ribbon/batch/queue_utils.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ): \"\"\" Generate a SLURM command to submit a job to the scheduler. Args: resources (dict): A dictionary of resources to request for the job. other_resources (dict): A dictionary of other resources to pass to the scheduler. job_variables (str): A string of environment variables to pass to the job. scheduler_script (str): The path to the script to run. Returns: str: The SLURM command to submit \"\"\" scheduler_command = 'sbatch' # Map resources to SLURM options resources_string = parse_slurm_resources ( resources ) # Add other resources as-is, from dict: for key , value in other_resources . items (): if value == '' : # If value is empty, assume it's a flag without a value resources_string += f \" { key } \" else : resources_string += f \" { key } = { value } \" # Construct the command command = f \" { scheduler_command } --export= { job_variables } { resources_string } { scheduler_script } \" return command parse_sge_resources ( resources , dependency_type = None ) Parse a dictionary of resources into a string of SGE options. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. Returns: str \u2013 A string of SGE options TODO: implement dependency handling Source code in ribbon/batch/queue_utils.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def parse_sge_resources ( resources , dependency_type = None ): \"\"\" Parse a dictionary of resources into a string of SGE options. Args: resources (dict): A dictionary of resources to request for the job. Returns: str: A string of SGE options TODO: implement dependency handling \"\"\" resource_mappings = { 'time' : '-l h_rt' , 'mem' : '-l mem_free' , 'dependency' : '-hold_jid' , 'gpus' : '-l gpu' , 'job-name' : '-N' , 'output' : '-o' , 'queue' : '-q' , 'node-name' : '-l hostname' , # Add other resource mappings as needed } # Parse dependencies: if 'dependency' in resources : dependencies = resources [ 'dependency' ] if isinstance ( dependencies , list ): dependencies = ',' . join ([ str ( job_id ) for job_id in dependencies ]) resources [ 'dependency' ] = dependencies resources_list = [] for key , value in resources . items (): if key == 'dependency' : # Handle dependencies specifically resources_list . append ( f \"-hold_jid { value } \" ) else : if key not in resource_mappings : print ( f \"Warning: Unrecognized resource key: { key } . Skipping.\" ) continue sge_option = resource_mappings . get ( key ) if sge_option : if sge_option . startswith ( '-l' ): resources_list . append ( f \" { sge_option } = { value } \" ) else : resources_list . append ( f \" { sge_option } { value } \" ) else : # For unrecognized keys, assume they are '-l key=value' resources_list . append ( f \"-l { key } = { value } \" ) resources_string = ' ' . join ( resources_list ) return resources_string parse_slurm_resources ( resources , dependency_type = 'afterok' ) Parse a dictionary of resources into a string of SLURM options. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. dependency_type ( str , default: 'afterok' ) \u2013 The type of dependency to use (e.g. 'afterok', 'afterany', 'afternotok') Returns: str \u2013 A string of SLURM options Source code in ribbon/batch/queue_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def parse_slurm_resources ( resources , dependency_type = 'afterok' ): \"\"\" Parse a dictionary of resources into a string of SLURM options. Args: resources (dict): A dictionary of resources to request for the job. dependency_type (str): The type of dependency to use (e.g. 'afterok', 'afterany', 'afternotok') Returns: str: A string of SLURM options \"\"\" resource_mappings = { 'time' : '--time' , 'mem' : '--mem' , 'dependency' : '--dependency' , 'gpus' : '--gpus' , 'job-name' : '--job-name' , 'requeue' : '--requeue' , 'output' : '--output' , 'queue' : '--partition' , 'node-name' : '--nodelist' , # Add other resource mappings as needed } # Parse dependencies: if 'dependency' in resources : dependencies = resources [ 'dependency' ] if isinstance ( dependencies , list ): dependencies = ':' . join ([ str ( job_id ) for job_id in dependencies ]) resources [ 'dependency' ] = dependency_type + ':' + dependencies resources_list = [] for key , value in resources . items (): if key not in resource_mappings : print ( f \"Warning: Unrecognized resource key: { key } . Skipping.\" ) continue slurm_option = resource_mappings . get ( key , key ) if value is True : # Flags without values resources_list . append ( f \" { slurm_option } \" ) else : resources_list . append ( f \" { slurm_option } = { value } \" ) resources_string = ' ' . join ( resources_list ) return resources_string sge_check_job_status ( job_ids ) Check if SGE jobs are still running or have completed. Parameters: job_ids ( list ) \u2013 A list of job IDs (as integers or strings) Returns: dict \u2013 A dictionary with job IDs as keys and statuses as values ('running' or 'completed') Source code in ribbon/batch/queue_utils.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def sge_check_job_status ( job_ids ): \"\"\" Check if SGE jobs are still running or have completed. Parameters: job_ids (list): A list of job IDs (as integers or strings) Returns: dict: A dictionary with job IDs as keys and statuses as values ('running' or 'completed') \"\"\" status_dict = {} for jobid in job_ids : try : # Run 'qstat -j <jobid>' and suppress output result = subprocess . run ( [ 'qstat' , '-j' , str ( jobid )], stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL ) if result . returncode == 0 : status = 'not completed' else : status = 'completed' status_dict [ jobid ] = status except Exception as e : status_dict [ jobid ] = f 'Error: { e } ' return status_dict slurm_check_job_status ( job_ids ) Check if SLURM jobs are still running or have completed. Parameters: job_ids ( list ) \u2013 A list of job IDs (as integers or strings) Returns: dict \u2013 A dictionary with job IDs as keys and statuses as values ('running' or 'completed') Source code in ribbon/batch/queue_utils.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 def slurm_check_job_status ( job_ids ): \"\"\" Check if SLURM jobs are still running or have completed. Parameters: job_ids (list): A list of job IDs (as integers or strings) Returns: dict: A dictionary with job IDs as keys and statuses as values ('running' or 'completed') \"\"\" status_dict = {} for jobid in job_ids : try : # Run 'squeue -j <jobid> --noheader' and capture the output. result = subprocess . run ( [ 'squeue' , '-j' , str ( jobid ), '--noheader' ], stdout = subprocess . PIPE , stderr = subprocess . DEVNULL , text = True ) # If any output is returned, the job is still in the queue (running or pending) if result . stdout . strip (): status = 'not completed' else : status = 'completed' status_dict [ jobid ] = status except Exception as e : status_dict [ jobid ] = f 'Error: { e } ' return status_dict","title":"Batch Processing"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.generate_sge_command","text":"Generate an SGE command to submit a job to the scheduler. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. other_resources ( dict ) \u2013 A dictionary of other resources to pass to the scheduler. job_variables ( str ) \u2013 A string of environment variables to pass to the job. scheduler_script ( str ) \u2013 The path to the script to run. Returns: str \u2013 The SGE command to submit Source code in ribbon/batch/queue_utils.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def generate_sge_command ( resources , other_resources , job_variables , scheduler_script ): \"\"\" Generate an SGE command to submit a job to the scheduler. Args: resources (dict): A dictionary of resources to request for the job. other_resources (dict): A dictionary of other resources to pass to the scheduler. job_variables (str): A string of environment variables to pass to the job. scheduler_script (str): The path to the script to run. Returns: str: The SGE command to submit \"\"\" scheduler_command = 'qsub' # Map resources to SGE options resources_string = parse_sge_resources ( resources ) # Add other resources as-is, from dict: for key , value in other_resources . items (): if value == '' : # If value is empty, assume it's a flag without a value resources_string += f \" { key } \" else : if key . startswith ( '-l' ): resources_string += f \" { key } = { value } \" else : resources_string += f \" { key } { value } \" # Construct the command command = f \" { scheduler_command } -v { job_variables } { resources_string } { scheduler_script } \" return command","title":"generate_sge_command"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.generate_slurm_command","text":"Generate a SLURM command to submit a job to the scheduler. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. other_resources ( dict ) \u2013 A dictionary of other resources to pass to the scheduler. job_variables ( str ) \u2013 A string of environment variables to pass to the job. scheduler_script ( str ) \u2013 The path to the script to run. Returns: str \u2013 The SLURM command to submit Source code in ribbon/batch/queue_utils.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def generate_slurm_command ( resources , other_resources , job_variables , scheduler_script ): \"\"\" Generate a SLURM command to submit a job to the scheduler. Args: resources (dict): A dictionary of resources to request for the job. other_resources (dict): A dictionary of other resources to pass to the scheduler. job_variables (str): A string of environment variables to pass to the job. scheduler_script (str): The path to the script to run. Returns: str: The SLURM command to submit \"\"\" scheduler_command = 'sbatch' # Map resources to SLURM options resources_string = parse_slurm_resources ( resources ) # Add other resources as-is, from dict: for key , value in other_resources . items (): if value == '' : # If value is empty, assume it's a flag without a value resources_string += f \" { key } \" else : resources_string += f \" { key } = { value } \" # Construct the command command = f \" { scheduler_command } --export= { job_variables } { resources_string } { scheduler_script } \" return command","title":"generate_slurm_command"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.parse_sge_resources","text":"Parse a dictionary of resources into a string of SGE options. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. Returns: str \u2013 A string of SGE options TODO: implement dependency handling Source code in ribbon/batch/queue_utils.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def parse_sge_resources ( resources , dependency_type = None ): \"\"\" Parse a dictionary of resources into a string of SGE options. Args: resources (dict): A dictionary of resources to request for the job. Returns: str: A string of SGE options TODO: implement dependency handling \"\"\" resource_mappings = { 'time' : '-l h_rt' , 'mem' : '-l mem_free' , 'dependency' : '-hold_jid' , 'gpus' : '-l gpu' , 'job-name' : '-N' , 'output' : '-o' , 'queue' : '-q' , 'node-name' : '-l hostname' , # Add other resource mappings as needed } # Parse dependencies: if 'dependency' in resources : dependencies = resources [ 'dependency' ] if isinstance ( dependencies , list ): dependencies = ',' . join ([ str ( job_id ) for job_id in dependencies ]) resources [ 'dependency' ] = dependencies resources_list = [] for key , value in resources . items (): if key == 'dependency' : # Handle dependencies specifically resources_list . append ( f \"-hold_jid { value } \" ) else : if key not in resource_mappings : print ( f \"Warning: Unrecognized resource key: { key } . Skipping.\" ) continue sge_option = resource_mappings . get ( key ) if sge_option : if sge_option . startswith ( '-l' ): resources_list . append ( f \" { sge_option } = { value } \" ) else : resources_list . append ( f \" { sge_option } { value } \" ) else : # For unrecognized keys, assume they are '-l key=value' resources_list . append ( f \"-l { key } = { value } \" ) resources_string = ' ' . join ( resources_list ) return resources_string","title":"parse_sge_resources"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.parse_slurm_resources","text":"Parse a dictionary of resources into a string of SLURM options. Parameters: resources ( dict ) \u2013 A dictionary of resources to request for the job. dependency_type ( str , default: 'afterok' ) \u2013 The type of dependency to use (e.g. 'afterok', 'afterany', 'afternotok') Returns: str \u2013 A string of SLURM options Source code in ribbon/batch/queue_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def parse_slurm_resources ( resources , dependency_type = 'afterok' ): \"\"\" Parse a dictionary of resources into a string of SLURM options. Args: resources (dict): A dictionary of resources to request for the job. dependency_type (str): The type of dependency to use (e.g. 'afterok', 'afterany', 'afternotok') Returns: str: A string of SLURM options \"\"\" resource_mappings = { 'time' : '--time' , 'mem' : '--mem' , 'dependency' : '--dependency' , 'gpus' : '--gpus' , 'job-name' : '--job-name' , 'requeue' : '--requeue' , 'output' : '--output' , 'queue' : '--partition' , 'node-name' : '--nodelist' , # Add other resource mappings as needed } # Parse dependencies: if 'dependency' in resources : dependencies = resources [ 'dependency' ] if isinstance ( dependencies , list ): dependencies = ':' . join ([ str ( job_id ) for job_id in dependencies ]) resources [ 'dependency' ] = dependency_type + ':' + dependencies resources_list = [] for key , value in resources . items (): if key not in resource_mappings : print ( f \"Warning: Unrecognized resource key: { key } . Skipping.\" ) continue slurm_option = resource_mappings . get ( key , key ) if value is True : # Flags without values resources_list . append ( f \" { slurm_option } \" ) else : resources_list . append ( f \" { slurm_option } = { value } \" ) resources_string = ' ' . join ( resources_list ) return resources_string","title":"parse_slurm_resources"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.sge_check_job_status","text":"Check if SGE jobs are still running or have completed. Parameters: job_ids ( list ) \u2013 A list of job IDs (as integers or strings) Returns: dict \u2013 A dictionary with job IDs as keys and statuses as values ('running' or 'completed') Source code in ribbon/batch/queue_utils.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def sge_check_job_status ( job_ids ): \"\"\" Check if SGE jobs are still running or have completed. Parameters: job_ids (list): A list of job IDs (as integers or strings) Returns: dict: A dictionary with job IDs as keys and statuses as values ('running' or 'completed') \"\"\" status_dict = {} for jobid in job_ids : try : # Run 'qstat -j <jobid>' and suppress output result = subprocess . run ( [ 'qstat' , '-j' , str ( jobid )], stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL ) if result . returncode == 0 : status = 'not completed' else : status = 'completed' status_dict [ jobid ] = status except Exception as e : status_dict [ jobid ] = f 'Error: { e } ' return status_dict","title":"sge_check_job_status"},{"location":"api/batch/batch/#ribbon.batch.queue_utils.slurm_check_job_status","text":"Check if SLURM jobs are still running or have completed. Parameters: job_ids ( list ) \u2013 A list of job IDs (as integers or strings) Returns: dict \u2013 A dictionary with job IDs as keys and statuses as values ('running' or 'completed') Source code in ribbon/batch/queue_utils.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 def slurm_check_job_status ( job_ids ): \"\"\" Check if SLURM jobs are still running or have completed. Parameters: job_ids (list): A list of job IDs (as integers or strings) Returns: dict: A dictionary with job IDs as keys and statuses as values ('running' or 'completed') \"\"\" status_dict = {} for jobid in job_ids : try : # Run 'squeue -j <jobid> --noheader' and capture the output. result = subprocess . run ( [ 'squeue' , '-j' , str ( jobid ), '--noheader' ], stdout = subprocess . PIPE , stderr = subprocess . DEVNULL , text = True ) # If any output is returned, the job is still in the queue (running or pending) if result . stdout . strip (): status = 'not completed' else : status = 'completed' status_dict [ jobid ] = status except Exception as e : status_dict [ jobid ] = f 'Error: { e } ' return status_dict","title":"slurm_check_job_status"},{"location":"usage/1_protein_folding/","text":"A Simple Example: Protein Folding For this series of tutorials, all the code will be in the examples directory in the repo . After installing , Apptainer and ribbon, use the code in /examples/example1 to follow along! Let's say we want to fold a protein from an amino acid sequence. We'll use Chai-1 , a high-accuracy, ligand aware protein folding method. This requires a gpu! First, we create a Task object, which sets up our Chai-1 job: import ribbon my_folding_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) Then, we run the Task : my_folding_task.run() This can be shortened to a single command: import ribbon ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ).run() Why the long wait? When you run a Task for the first time, Ribbon will download all of the relevant software and scripts to your computer inside of a virtual machine. This only happens once !","title":"A Simple Example: Protein Folding"},{"location":"usage/1_protein_folding/#a-simple-example-protein-folding","text":"For this series of tutorials, all the code will be in the examples directory in the repo . After installing , Apptainer and ribbon, use the code in /examples/example1 to follow along! Let's say we want to fold a protein from an amino acid sequence. We'll use Chai-1 , a high-accuracy, ligand aware protein folding method. This requires a gpu! First, we create a Task object, which sets up our Chai-1 job: import ribbon my_folding_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) Then, we run the Task : my_folding_task.run() This can be shortened to a single command: import ribbon ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ).run() Why the long wait? When you run a Task for the first time, Ribbon will download all of the relevant software and scripts to your computer inside of a virtual machine. This only happens once !","title":"A Simple Example: Protein Folding"},{"location":"usage/2_pipelining/","text":"Let's Get Pipelining Since running a job is so simple, we can string many jobs together into a pipeline . (Code: /examples/example2 ) For example, we'll start with an initial PDB structure. We'll redesign the sequence using LigandMPNN, which will output several FASTA files that it thinks could fold into our input structure: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ).run() I wonder how well LigandMPNN did? We can easily fold these sequences using the fast RaptorX-Single software: ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx' ).run() Chaining these together, we get our first protein design pipeline: import ribbon # First, we create 5 new sequences for this structure: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ).run() # These sequences are split into individual files, and are stored in 'out/seqs_split' # Then, we fold using RaptorX: ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx' ).run() What are these files? Certain Tasks need to create temporary files in the current directory while running (Such as a the LigandMPNN/ folder, or RaptorX-Single symlink). In the future, I'd like Ribbon to clean these up better. For now, these files are safe to delete as long as no Tasks are running .","title":"Let's Get Pipelining"},{"location":"usage/2_pipelining/#lets-get-pipelining","text":"Since running a job is so simple, we can string many jobs together into a pipeline . (Code: /examples/example2 ) For example, we'll start with an initial PDB structure. We'll redesign the sequence using LigandMPNN, which will output several FASTA files that it thinks could fold into our input structure: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ).run() I wonder how well LigandMPNN did? We can easily fold these sequences using the fast RaptorX-Single software: ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx' ).run() Chaining these together, we get our first protein design pipeline: import ribbon # First, we create 5 new sequences for this structure: ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ).run() # These sequences are split into individual files, and are stored in 'out/seqs_split' # Then, we fold using RaptorX: ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx' ).run() What are these files? Certain Tasks need to create temporary files in the current directory while running (Such as a the LigandMPNN/ folder, or RaptorX-Single symlink). In the future, I'd like Ribbon to clean these up better. For now, these files are safe to delete as long as no Tasks are running .","title":"Let's Get Pipelining"},{"location":"usage/3_queueing_part_1/","text":"Queueing Pt. 1: Submitting Jobs If we want to run hundreds or thousands of Tasks , it's impractical to run them one-by-one. We can use a scheduler like SLURM or SGE to queue Tasks (called jobs, in this context). A high-performance compute cluster will use one of these tools to manage jobs. (Code: /examples/example3 ) In this tutorial, we will not cover how to use SGE or SLURM. We recommend becoming familiar with these tools on your compute cluster before continuing. To start, let's make a new Task object to fold a protein with Chai-1: import ribbon my_folding_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) Before, we ran the task locally using my_folding_task.run() . To queue the job, we instead use the .queue() function: my_folding_task.queue( scheduler='SLURM', ) In this case, I've specified that the scheduler our cluster is using is SLURM. Let's instead submit a job to an SGE cluster. We can also specify add a job name and a named output file. Additionally, let's make sure we're running on the GPU queue for our cluster, and ask only for nodes that have an A40 GPU. Finally, we'll have our job quit early if it runs longer than 30 minutes. my_folding_task.queue( scheduler='SGE', queue='gpu.q', job_name='my_chai1_job', output_file='my_chai1_job.out', node_name = 'qb3-atgpu*', time='00:30:00') Putting it all together: import ribbon my_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) my_task.queue(scheduler='SGE', job_name='my_chai1_job', output_file='my_chai1_job.out', time='00:30:00', queue='gpu.q') RTFM These specific parameters (including queue and node names) will vary for your compute cluster. Make sure to read your cluster's documentation, and test using the SLURM or SGE command line interface.","title":"Queueing Pt. 1: Submitting Jobs"},{"location":"usage/3_queueing_part_1/#queueing-pt-1-submitting-jobs","text":"If we want to run hundreds or thousands of Tasks , it's impractical to run them one-by-one. We can use a scheduler like SLURM or SGE to queue Tasks (called jobs, in this context). A high-performance compute cluster will use one of these tools to manage jobs. (Code: /examples/example3 ) In this tutorial, we will not cover how to use SGE or SLURM. We recommend becoming familiar with these tools on your compute cluster before continuing. To start, let's make a new Task object to fold a protein with Chai-1: import ribbon my_folding_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) Before, we ran the task locally using my_folding_task.run() . To queue the job, we instead use the .queue() function: my_folding_task.queue( scheduler='SLURM', ) In this case, I've specified that the scheduler our cluster is using is SLURM. Let's instead submit a job to an SGE cluster. We can also specify add a job name and a named output file. Additionally, let's make sure we're running on the GPU queue for our cluster, and ask only for nodes that have an A40 GPU. Finally, we'll have our job quit early if it runs longer than 30 minutes. my_folding_task.queue( scheduler='SGE', queue='gpu.q', job_name='my_chai1_job', output_file='my_chai1_job.out', node_name = 'qb3-atgpu*', time='00:30:00') Putting it all together: import ribbon my_task = ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ) my_task.queue(scheduler='SGE', job_name='my_chai1_job', output_file='my_chai1_job.out', time='00:30:00', queue='gpu.q') RTFM These specific parameters (including queue and node names) will vary for your compute cluster. Make sure to read your cluster's documentation, and test using the SLURM or SGE command line interface.","title":"Queueing Pt. 1: Submitting Jobs"},{"location":"usage/3_queueing_part_2/","text":"Queueing Pt. 2: Linking Jobs Often, we'll want to run Tasks one after the other, where each depends on the previous. Like in (Let's get Pipelining), this allows us to form complex protein design pipelines. In this example, we'll schedule a job to generate protein sequences using LigandMPNN, and schedule a subsequent job to fold the sequences using RaptorX-Single. (Code: /examples/example4 ) We'll start as before, defining a LigandMPNN Task : import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) Then, we'll queue this task. The queue() function returns the job id , which is a unique identifier for the job we've submitted to the scheduler. lmpnn_job_id = lmpnn_task.queue(scheduler='SGE') We create and submit a RaptorX-Single Task , using the depends_on parameter to pass in a list of job IDs. raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SGE' depends_on = [lmpnn_job_id] ) Dependency Types By default, the job will only run after all dependencies complete successfully . If using SLURM, more complex behavior can be set using the dependency_type parameter, which takes standard SLURM dependency types (default: afterok ). Here's our script completed: import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) # We'll queue the job, and get the job ID lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM', depends_on = [lmpnn_job_id] )","title":"Queueing Pt. 2: Linking Jobs"},{"location":"usage/3_queueing_part_2/#queueing-pt-2-linking-jobs","text":"Often, we'll want to run Tasks one after the other, where each depends on the previous. Like in (Let's get Pipelining), this allows us to form complex protein design pipelines. In this example, we'll schedule a job to generate protein sequences using LigandMPNN, and schedule a subsequent job to fold the sequences using RaptorX-Single. (Code: /examples/example4 ) We'll start as before, defining a LigandMPNN Task : import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) Then, we'll queue this task. The queue() function returns the job id , which is a unique identifier for the job we've submitted to the scheduler. lmpnn_job_id = lmpnn_task.queue(scheduler='SGE') We create and submit a RaptorX-Single Task , using the depends_on parameter to pass in a list of job IDs. raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SGE' depends_on = [lmpnn_job_id] ) Dependency Types By default, the job will only run after all dependencies complete successfully . If using SLURM, more complex behavior can be set using the dependency_type parameter, which takes standard SLURM dependency types (default: afterok ). Here's our script completed: import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) # We'll queue the job, and get the job ID lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM', depends_on = [lmpnn_job_id] )","title":"Queueing Pt. 2: Linking Jobs"},{"location":"usage/3_queueing_part_3/","text":"Queueing Pt. 3: Mixed Submission As seen in the previous tutorial, we can link together complex sets of jobs using the depends_on flag. In this way, we can submit many interdependent jobs ahead of time. (Code: /examples/example5 ) However, it's sometimes useful to run small snippets of python code between jobs, or to have programmatic checks to make sure everything's running smoothly (before we submit thousands of jobs that inevitably fail due to a typo). In these instances, we can use a mixed submission strategy. Rather than submitting all of our Tasks to a scheduler at the start, we can queue a set of jobs, wait for them to finish, and check on or modify the results before submitting further jobs. In this example, we'll predict sequences using LigandMPNN, but before we fold them with RaptorX-Single, we'll apply mutations to those sequences using a simple python function. We start by queueing our first job: import ribbon lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') Then we'll use ribbon.wait_for_jobs() , to pause our script until our jobs have completed successfully: ribbon.wait_for_jobs([lmpnn_job_id], queue='SLURM') This simple function periodically queries the scheduler, keeping track of the status of our jobs. After all of our jobs have completed, we apply a small mutation to each using the following script: position = 10 mutation = 'A' import os os.mkdir('./out/lmpnn/seqs_split_mutated') for f in os.listdir('./out/lmpnn/seqs_split'): with open(os.path.join('./out/lmpnn/seqs_split', f)) as infile, open(os.path.join('./out/lmpnn/seqs_split_mutated', f), 'w') as outfile: for line in infile: outfile.write(line if line.startswith('>') else line[:position-1] + mutation + line[position:]) You'll likely want at more sophisticated method for mutagenesis - but for a tutorial, this will suffice! Now, we can fold these mutated structures, as before: # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn/seqs_split', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM', depends_on = [lmpnn_job_id] ) All together, our final script looks like: import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) # We'll queue the job, and get the job ID lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') # Wait for it to finish: ribbon.wait_for_jobs([lmpnn_job_id], scheduler='SLURM') # For all of our output FASTAs, apply a mutation: position = 10 mutation = 'A' import os os.mkdir('./out/lmpnn/seqs_split_mutated') for f in os.listdir('./out/lmpnn/seqs_split'): with open(os.path.join('./out/lmpnn/seqs_split', f)) as infile, open(os.path.join('./out/lmpnn/seqs_split_mutated', f), 'w') as outfile: for line in infile: outfile.write(line if line.startswith('>') else line[:position-1] + mutation + line[position:]) # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn/seqs_split', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM' ) If we execute this script manually, it will run until the final jobs are queued. However, if this script exits prematurely - for example, if your ssh connection closes, your final jobs may not be queued. To overcome this limitation, we can submit this script as the primary SLURM job, which queues the LigandMPNN and RaptorX-Single Tasks as secondary jobs. After saving our script, we can create a minimal SLURM submission script called submit.sh : #!/bin/bash conda activate ribbon python mixed_scheduling.py And submit our primary job with the SLURM command-line interface: sbatch submit.sh","title":"Queueing Pt. 3: Mixed Submission"},{"location":"usage/3_queueing_part_3/#queueing-pt-3-mixed-submission","text":"As seen in the previous tutorial, we can link together complex sets of jobs using the depends_on flag. In this way, we can submit many interdependent jobs ahead of time. (Code: /examples/example5 ) However, it's sometimes useful to run small snippets of python code between jobs, or to have programmatic checks to make sure everything's running smoothly (before we submit thousands of jobs that inevitably fail due to a typo). In these instances, we can use a mixed submission strategy. Rather than submitting all of our Tasks to a scheduler at the start, we can queue a set of jobs, wait for them to finish, and check on or modify the results before submitting further jobs. In this example, we'll predict sequences using LigandMPNN, but before we fold them with RaptorX-Single, we'll apply mutations to those sequences using a simple python function. We start by queueing our first job: import ribbon lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') Then we'll use ribbon.wait_for_jobs() , to pause our script until our jobs have completed successfully: ribbon.wait_for_jobs([lmpnn_job_id], queue='SLURM') This simple function periodically queries the scheduler, keeping track of the status of our jobs. After all of our jobs have completed, we apply a small mutation to each using the following script: position = 10 mutation = 'A' import os os.mkdir('./out/lmpnn/seqs_split_mutated') for f in os.listdir('./out/lmpnn/seqs_split'): with open(os.path.join('./out/lmpnn/seqs_split', f)) as infile, open(os.path.join('./out/lmpnn/seqs_split_mutated', f), 'w') as outfile: for line in infile: outfile.write(line if line.startswith('>') else line[:position-1] + mutation + line[position:]) You'll likely want at more sophisticated method for mutagenesis - but for a tutorial, this will suffice! Now, we can fold these mutated structures, as before: # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn/seqs_split', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM', depends_on = [lmpnn_job_id] ) All together, our final script looks like: import ribbon # First, we create 5 new sequences for this structure: lmpnn_task = ribbon.LigandMPNN( structure_list = ['my_structure.pdb'], output_dir = './out/lmpnn', num_designs = 5 ) # We'll queue the job, and get the job ID lmpnn_job_id = lmpnn_task.queue(scheduler='SLURM') # Wait for it to finish: ribbon.wait_for_jobs([lmpnn_job_id], scheduler='SLURM') # For all of our output FASTAs, apply a mutation: position = 10 mutation = 'A' import os os.mkdir('./out/lmpnn/seqs_split_mutated') for f in os.listdir('./out/lmpnn/seqs_split'): with open(os.path.join('./out/lmpnn/seqs_split', f)) as infile, open(os.path.join('./out/lmpnn/seqs_split_mutated', f), 'w') as outfile: for line in infile: outfile.write(line if line.startswith('>') else line[:position-1] + mutation + line[position:]) # Then, we create and queue a RaptorX Task: raptorx_task = ribbon.RaptorXSingle( fasta_file_or_dir = './out/lmpnn/seqs_split', output_dir = './out/raptorx', ) raptorx_task.queue( scheduler='SLURM' ) If we execute this script manually, it will run until the final jobs are queued. However, if this script exits prematurely - for example, if your ssh connection closes, your final jobs may not be queued. To overcome this limitation, we can submit this script as the primary SLURM job, which queues the LigandMPNN and RaptorX-Single Tasks as secondary jobs. After saving our script, we can create a minimal SLURM submission script called submit.sh : #!/bin/bash conda activate ribbon python mixed_scheduling.py And submit our primary job with the SLURM command-line interface: sbatch submit.sh","title":"Queueing Pt. 3: Mixed Submission"},{"location":"usage/4_custom_tasks/","text":"","title":"4 custom tasks"},{"location":"usage/getting_started/","text":"How to use Ribbon Ribbon is an easy-to-use python package, which simplifies the installation and running of protein design software. Want to fold a protein? Once Ribbon is installed , it's as easy as: import ribbon ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ).run() To get started, move on to our initial tutorial: A Simple Example: Protein Folding","title":"How to use Ribbon"},{"location":"usage/getting_started/#how-to-use-ribbon","text":"Ribbon is an easy-to-use python package, which simplifies the installation and running of protein design software. Want to fold a protein? Once Ribbon is installed , it's as easy as: import ribbon ribbon.Chai1( fasta_file = 'my_sequence.fasta', # Input FASTA output_dir = './out' # Where the outputs will be stored ).run() To get started, move on to our initial tutorial: A Simple Example: Protein Folding","title":"How to use Ribbon"}]}